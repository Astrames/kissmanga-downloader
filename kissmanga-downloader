#!/usr/bin/env python

import os, time, sys, re
import pdfMaker
import argparse
import urllib.request

from selenium import webdriver

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.support.ui import Select
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities


"""
sample url = 
http://kissmanga.com/Manga/Sensei-Lock-On
http://kissmanga.com/Manga/Dragon-Ball
"""
class ClassName(object):
    """docstring for ClassName"""
    def __init__(self, arg):
        super(ClassName, self).__init__()
        self.arg = arg
        

class  DriverX(object):
    """docstring for  driverX"""
    def __init__(self):
        super(DriverX, self).__init__()
        self.driver = init_driver()

    def __enter__(self):
        return self.driver

    def __exit__(self, type, value, traceback):
        pass    


def init_driver():
    """
    Returns a driver object.
    """

    # Setting the user agent to a human browser
    options = webdriver.ChromeOptions()
    options.add_argument('headless')
    options.add_argument("user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53")

    driver = webdriver.Chrome(chrome_options=options)

    return driver


def get_title_and_chapter_links(driver, url_to_series):
    """
    Supply the main page of the manga and get the title, and list of URLs
    of the chapters available
    """
    driver.get(url_to_series)

    try:
        title_tag = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME,"bigChar")))
        title_text = title_tag.text
    except TimeoutException:
        print("Exception Occured:    TimeoutException")
        sys.exit("Couldn't get title!")

    list_of_a_tags = driver.find_elements_by_xpath("//tbody/tr/td/a")

    # Reversing to get ascending list,
    # since it is originally in descending order
    list_of_a_tags = list_of_a_tags[::-1]

    list_of_href = []
    for a_tag in list_of_a_tags:
        list_of_href.append(a_tag.get_attribute('href'))

    return title_text, list_of_href


def download_pages_of_one_chapter(driver, url_to_chapter):
    """
    Goes through the chapter and downloads each page it encounters
    """

    # Going to first page
    driver.get(url_to_chapter)

    try:
        drop_down_list = WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.ID,"selectReadType")))
    except TimeoutException:
        print("Exception Occured:    TimeoutException")
        sys.exit("Couldn't load chapter!")
 
    select = Select(drop_down_list)

    # Selecting the 'All Pages' option
    select.select_by_value('1')

    list_of_page_img = driver.find_elements_by_xpath('//div[@id="divImage"]/p/img')

    chapter_name = url_to_chapter[url_to_chapter.rfind('/') + 1 : url_to_chapter.rfind('?')]

    # Unify format by parsing number out of chapter_name
    chapter_folder_name = "Chapter-" + re.findall('\d+', chapter_name)[0]
    
    

    # print("Chapter name is " + chapter_name)

    # Create folder for chapter , if it not exist
    if not os.path.exists(chapter_folder_name):
        os.makedirs(chapter_folder_name)

    print("Chapter "+ chapter_name + " -> " + chapter_folder_name + os.pathsep)
    
    page_no = 1
    for page in list_of_page_img:
    
        page_no_correct = str(page_no).zfill(3)
        url = page.get_attribute("src")
        filepath = os.path.join(chapter_folder_name, page_no_correct + ".jpg")

        # Current folder
        pwd = os.path.dirname(os.path.realpath(__file__))
        #Creating full file name
        fullfilename = os.path.join(pwd, filepath)
        
        if os.path.exists(fullfilename):
            print(" " + page_no_correct + "(exists)", end="")
        else:
            print(" " + page_no_correct, end="")
            try:
                req = urllib.request.Request(url, headers={'User-Agent' : "Magic Browser"})
                con = urllib.request.urlopen(req)
                with open(fullfilename, mode="wb") as d:
                    d.write(con.read())
            except:
                # Skip, not available
                print("(error)", end="")
            
        sys.stdout.flush()
        page_no += 1

    print()
    print()
    
    pass
    
def create_series_folder(title):
     if not os.path.exists(title):
        print(title +" folder didnt exist, it has been created")
        os.makedirs(title)

def dequote(s):
    """
    If a string has single or double quotes around it, remove them.
    Make sure the pair of quotes match.
    If a matching pair of quotes is not found, return the string unchanged.
    """
    if (s[0] == s[-1]) and s.startswith(("'", '"')):
        return s[1:-1]
    return s

def process(driver):
    base_url = "https://kissmanga.com/Manga/"
    
    # Parse arguments
    parser = argparse.ArgumentParser(description="Batch-download chapters and series from Kissmanga")
    parser.add_argument('-u', '--url', required=True, type=str, help="Name of the series, no need to include the base kissmanga URL, so for 'https://kissmanga.com/Manga/Dragon-Ball' use'Dragon-Ball)")
    parser.add_argument('-i', '--ini', required=True, type=int, help="Initial chapter number to download, in [1..n]")
    parser.add_argument('-e', '--end', required=True, type=int, help="Final chapter number to download, included")
    parser.add_argument('--pdf', required=False, action='store_true', help="Generate a PDF file for each chapter")
    parser.add_argument('--pdfseries', required=False, action='store_true', help="Generate a huge PDF file with all chapters")
    parser.add_argument('--pagezero', required=False, action='store_true', help="Create title page for each chapter")
    parser.add_argument('--ow', required=False, action='store_true', help="Overwrite existing PDF files")

    args = parser.parse_args()

    # Get main page of the series

    print("Initialising kissmanga-downloader")

    url = args.url if 'kissmanga.com' in dequote(args.url) else base_url + dequote(args.url)

    title, list_of_hrefs = get_title_and_chapter_links(driver, url)

    # Create folder for the series, if it doesn't exist
    create_series_folder(title)

    # Starting folder
    start_folder = os.getcwd()

    # Navigate inside the series folder
    os.chdir(title)

    low_index = args.ini
    high_index = args.end

    if low_index < 1:
        print("--ini must be larger than 0: " + low_index)
        exit(0)

    if high_index < low_index:
        print("--end must be greater or equal than --ini: [%d <= %d]" % (low_index, high_index))
        exit(0)

    required_list = list_of_hrefs[low_index - 1: high_index - 1]

    print()

    # Iterate over the list_of_hrefs for the requested chapters
    for href in required_list:
        # Download a chapter
        download_pages_of_one_chapter(driver, href)

    print("Chapters downloaded")
    driver.quit()

    print("Creating PDFs now...\n")

    if args.pdf:
        # Active directory is inside the series folder:
        # Create the PDF, from the chapters inside
        mypath = os.getcwd()
        for root, dirs, files in os.walk(mypath):
            for single_dir in dirs:
                pdfMaker.create_pdf(imageDirectory=single_dir,
                                    bool_page0=args.pagezero,
                                    overwriteExisting=args.ow)


    if args.pdfseries:
        # Current folder has all the .pdf of the chapter folders
        pdfMaker.merge_pdfs(os.getcwd())

    # Go back to start_folder
    os.chdir(start_folder)

    print("Done!")
    

if __name__ == '__main__':
    with DriverX() as driver:
        process(driver)
